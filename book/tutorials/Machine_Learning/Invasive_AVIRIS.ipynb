{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "682d514b-d10e-4cbe-b3b5-bc7d8d589dcf",
   "metadata": {},
   "source": [
    "# Mapping invasive species using supervised machine learning and AVIRIS-NG \n",
    "\n",
    "## Overview \n",
    "\n",
    "In this notebook, we will use existing data of verified land cover and alien species locations to extract spectra from AVIRIS NG surface reflectance data.\n",
    "\n",
    "## Learning Objectives\n",
    "1. Understand how to inspect and prepare data for machine learning models\n",
    "2. Train and interpret a machine learning model\n",
    "3. Apply a trained model to AVIRIS imagery to create alien species maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bcc04b-ede1-44ce-8e6e-694f774e6e5e",
   "metadata": {},
   "source": [
    "### Load python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb49bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from shapely.geometry import box, mapping\n",
    "import rioxarray as riox\n",
    "import numpy as np\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import xvec\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "hvplot.extension('bokeh')\n",
    "%matplotlib inline\n",
    "\n",
    "#our functions\n",
    "#processes a multi-file datase\n",
    "#to extract the first valid reflectance measurement for each geometry. \n",
    "#iterates through the data, identifying the first non-null entry for each geometry across all files, \n",
    "#and then selects those specific reflectance values. \n",
    "\n",
    "def get_first_xr(ds_in):\n",
    "    #array with geomtery x files\n",
    "    arr = ds_in['index'].data\n",
    "    \n",
    "    #we want to find the first file where the geom is not null\n",
    "    # Initialize an array to store the indices of the first non-null entry for each column\n",
    "    file_ind = np.full(arr.shape[1], -1)  # Using -1 as a placeholder for no non-null values\n",
    "    \n",
    "    # Iterate over each column\n",
    "    for col_idx in range(arr.shape[1]):\n",
    "        # Get the column\n",
    "        col = arr[:, col_idx]\n",
    "        \n",
    "        # Find the index of the first non-null entry\n",
    "        non_null_indices = np.where(~np.isnan(col))[0]\n",
    "        \n",
    "        if non_null_indices.size > 0:\n",
    "            file_ind[col_idx] = non_null_indices[0]\n",
    "    \n",
    "    #create a list form 0 to len first_non_null_indices\n",
    "    geom_ind = list(range(len(file_ind)))\n",
    "    \n",
    "    file_ind = xr.DataArray(file_ind, dims=[\"index\"])\n",
    "    geom_ind = xr.DataArray(geom_ind, dims=[\"index\"])\n",
    "    \n",
    "    ds = ds_in['reflectance'][file_ind, geom_ind, :]\n",
    "    ds['index'] = ds['index'].astype(int)\n",
    "    #convert to dataset\n",
    "    ds = ds.to_dataset(name='reflectance')\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe17082-4bea-4f3e-9faa-066c02392111",
   "metadata": {},
   "source": [
    "#### Open and inspect invasives data \n",
    "In this exercise we will be using a small dataset of manually collected invasive plant and land cover labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebfed43-b654-43b8-b61c-e0242f279c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually link the labels to the class\n",
    "\n",
    "text_lab = ['Bare ground/Rock','Mature Fynbos','Recently burnt Fynbos','Wetland','Forest','Pine','Eucalyptus','Wattle','Water']\n",
    "label = ['0','1','2','3','4','5','6','7','8']\n",
    "\n",
    "lab_df = pd.DataFrame({\n",
    "    'class': label,\n",
    "    'text_lab': text_lab\n",
    "})\n",
    "lab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74aa2ca-ff55-473b-ab21-0ad9f197c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the data\n",
    "raw_data = gpd.read_file('shared/users/gmoncrieff/data/ct_invasive.gpkg')\n",
    "raw_data_utm = (raw_data\n",
    "                .to_crs(\"EPSG:32734\")\n",
    "                .merge(lab_df, on='class', how='left')\n",
    "               )\n",
    "raw_data_utm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore data in interactive map. color by class. use google sattelite basemap\n",
    "(raw_data_utm[['text_lab','geometry']]\n",
    " .explore('text_lab',tiles='https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}', attr='Google'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638eb943-1aa9-4785-8719-eb467587ab64",
   "metadata": {},
   "source": [
    "#### find AVIRIS data\n",
    "The Bioscape AVIRIS data is not yet stored in a publically searchable place like EMIT. We will need to use some extra data to figure out which AVIRIS scenes we want to work with. We have a coverage file which has the footprints of each AVIRIS scene. The flights we are interested in took place over the Cape Pensinsula on 2023-11-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cff15df-1501-478e-970d-108bdd718476",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVNG_Coverage = gpd.read_file('shared/users/gmoncrieff/data/ANG_Coverage.geojson')\n",
    "#filter dates to between midnight on 2023-11-09 and 23:59:59 on 2023-11-09\n",
    "AVNG_CP = AVNG_Coverage[(AVNG_Coverage['end_time'] >= '2023-11-09 00:00:00') & (AVNG_Coverage['end_time'] <= '2023-11-09 23:59:59')]\n",
    "#keep only AVNG_CP that intersects with raw_data\n",
    "AVNG_CP = AVNG_CP[AVNG_CP.intersects(raw_data.union_all())]\n",
    "\n",
    "#make a list of filenames\n",
    "files = AVNG_CP['RFL s3'].tolist()\n",
    "files.pop(70)\n",
    "\n",
    "#filter to start time between\n",
    "(AVNG_CP[['fid','geometry']]\n",
    " .explore('fid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f40db",
   "metadata": {},
   "source": [
    "Open a single file to inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd0616-6d4a-4043-a3f2-3cba1abe1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xr.open_dataset(files[30], engine='kerchunk', chunks='auto')\n",
    "test = test.where(test>0)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f191d52",
   "metadata": {},
   "source": [
    "Plot a True Color image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b1743-3c9b-4590-bff3-3aafc643b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sel(wavelength=[660, 570, 480], method=\"nearest\").hvplot.rgb('x', 'y',\n",
    "                                                                  rasterize=True,data_aspect=1,robust=True,\n",
    "                                                                  bands='wavelength',frame_width=400\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbbf0b1",
   "metadata": {},
   "source": [
    "Plot the red reflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967ae98-bdc3-4934-8869-70bc7a7a0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sel({'wavelength': 660},method='nearest').hvplot('x', 'y',\n",
    "                                                      rasterize=True, data_aspect=1,robust=True,\n",
    "                                                      cmap='magma',frame_width=400\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4587f72",
   "metadata": {},
   "source": [
    "Now that we are happy with the data, we want to get the AVIRIS spectra at each label location. Below is a function that does this and returns the result as a xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4232e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function takes a filepath to a file on s3, and the point locations for extraction\n",
    "def extract_points(file,points):\n",
    "    \n",
    "    ds = xr.open_dataset(file, engine='kerchunk', chunks='auto')\n",
    "    \n",
    "    # Get the bounding box coordinates\n",
    "    left, bottom, right, top = ds.rio.bounds()\n",
    "    \n",
    "    # Create a Shapely box geometry\n",
    "    bbox_shapely = box(left, bottom, right, top)\n",
    "    \n",
    "    # Clip the raw data to the bounding box\n",
    "    points = points.clip(bbox_shapely)\n",
    "    print(f'got {points.shape[0]} point from {file}')\n",
    "    \n",
    "    # Extract points\n",
    "    extracted = ds.xvec.extract_points(points['geometry'], x_coords=\"x\", y_coords=\"y\",index=True)\n",
    "    \n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce26583",
   "metadata": {},
   "source": [
    "Now we iterate through the list of files. Each files only overlaps with a few of the points, but all the files will eventually cover all the points once we combine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba10bc-5ba3-4fa1-8cd1-f2261cf13bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all = [extract_points(file,raw_data_utm) for file in files]\n",
    "\n",
    "#combine the results into a single xarray\n",
    "ds_all  = xr.concat(ds_all, dim='file')\n",
    "ds_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105bd2fa",
   "metadata": {},
   "source": [
    "Because some points are covered by multiple AVIRIS scenes, some points have multiple spectra for each location, and thus we have an extra dim in this. We will simply extract the first valid reflectance measurement for each geometry. We have a custom function to do this `get_first_xr()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284703b-58d3-467f-9167-0f42ba74c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds = get_first_xr(ds_all)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710178fd",
   "metadata": {},
   "source": [
    "This data set just has the spectra. We need to merge with point data to add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e7c9c-4c36-44d0-a572-7133699657fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_xr =raw_data_utm[['class','group']].to_xarray()\n",
    "ds = ds.merge(class_xr.astype(int),join='left')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10af9a1",
   "metadata": {},
   "source": [
    "We have defined all the operations we want, but becasue of xarrays lazy compution, the calculations have not yet been done. We will now force it to perform this calculations. We want to keep the result in chunks, so we use `.persist()` and not `.compute()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf47817",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    " dsp = ds.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34af28ea-8400-4496-8496-fbdc3e1ba039",
   "metadata": {},
   "source": [
    "#### Inspect AVIRIS spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp_plot = dsp.where(dsp['class']==0, drop=True)\n",
    "dsp_plot['reflectance'].hvplot.line(x='wavelength',by='index',\n",
    "                                    color='green',ylim=(0,0.5),alpha=0.5,legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815c8fcd-a083-45b1-818b-48afa04bf907",
   "metadata": {},
   "source": [
    "> At this point in a real machine learning workflow, you should closely inspect the spectra you have for each class. Do they make sense? Are there some spectra that look weird? You should re-evaluate your data to make sure that the assigned labels are true. This is a very important step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c07268-1b4d-462a-a2a0-853afbdb86c1",
   "metadata": {},
   "source": [
    "#### Prep data for ML model\n",
    "\n",
    "As you will know, not all of the wavelengths in the data are of equal quality, some will be degraded by atmospheric water absorption features or other factors. We should remove the bands from the analysis that we are not confident of. Probably the best way to do this is to use the uncertainties provided along with the reflectance files. We will simply use some prior knowledge to screen out the worst bands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a86ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelengths_to_drop = ds.wavelength.where(\n",
    "    (ds.wavelength < 420) |\n",
    "    (ds.wavelength >= 1340) & (ds.wavelength <= 1450) |\n",
    "    (ds.wavelength >= 1800) & (ds.wavelength <= 1980) |\n",
    "    (ds.wavelength > 2400), drop=True\n",
    ")\n",
    "\n",
    "# Use drop_sel() to remove those specific wavelength ranges\n",
    "dsp = dsp.drop_sel(wavelength=wavelengths_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67a5dd",
   "metadata": {},
   "source": [
    "Next we will normalize the data, there are a number of difference normalizations to try. In a ML workflow you should try a few and see which work best. We will only use a Brightness Normalization. In essence, we scale the reflectance of each wavelength by the total brightness of the spectra. This retains info on important shape features and relative reflectance, and removes info on absolute reflectance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2724352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the L2 norm along the 'wavelength' dimension in a Dask-aware way\n",
    "l2_norm = np.sqrt((dsp['reflectance'] ** 2).sum(dim='wavelength'))\n",
    "\n",
    "# Normalize the reflectance by dividing by the L2 norm\n",
    "dsp['reflectance'] = dsp['reflectance'] / l2_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7024d354",
   "metadata": {},
   "source": [
    "Plot our new, clean spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp_norm_plot = dsp.where(dsp['class']==4, drop=True)\n",
    "dsp_norm_plot['reflectance'].hvplot.line(x='wavelength',by='index',\n",
    "                                         color='green',ylim=(0,0.2),alpha=0.5,legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fa6a0-f5f8-46c4-bee8-d11847c88876",
   "metadata": {},
   "source": [
    "#### Train and evaluate ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac715b",
   "metadata": {},
   "source": [
    "We will be using a model called `xgboost`. There are many, many different kinds of ML models. `xgboost` is a class of models called gradient boosted trees, related to random forests. When used for classification, random forests work by creating multiple decision trees, each trained on a random subset of the data and features, and then averaging their predictions to improve accuracy and reduce overfitting. Gradient boosted trees differ in that they build trees sequentially, with each new tree focusing on correcting the errors of the previous ones. This sequential approach allows `xgboost` to create highly accurate models by iteratively refining predictions and addressing the weaknesses of earlier trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9506f75d",
   "metadata": {},
   "source": [
    "Import the Machine Learning libraries we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53485c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d959c1",
   "metadata": {},
   "source": [
    "Our dataset has a label indicating which set (training or test), our data belong to. We wil use this to split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4036f9bb-aaa7-429c-a4f8-663296cd1e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = dsp.where(dsp['group']==1,drop=True)\n",
    "dtest = dsp.where(dsp['group']==2,drop=True)\n",
    "\n",
    "#create separte datasets for labels and features\n",
    "y_train = dtrain['class'].values.astype(int)\n",
    "y_test = dtest['class'].values.astype(int)\n",
    "X_train = dtrain['reflectance'].values\n",
    "X_test = dtest['reflectance'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2b371",
   "metadata": {},
   "source": [
    "#### Train ML model\n",
    "The steps we will go through to train the model are:\n",
    "\n",
    "First, we define the hyperparameter grid. Initially, we set up a comprehensive grid (param_grid) with multiple values for several hyperparameters of the XGBoost model. \n",
    "\n",
    "Next, we create an XGBoost classifier object using the XGBClassifier class from the XGBoost library.\n",
    "\n",
    "We then set up the GridSearchCV object using our defined XGBoost model and the hyperparameter grid. GridSearchCV allows us to perform an exhaustive search over the specified hyperparameter values to find the optimal combination that results in the best model performance. We choose a 5-fold cross-validation strategy (cv=5), meaning we split our training data into five subsets to validate the model's performance across different data splits. We use accuracy as our scoring metric to evaluate the models.\n",
    "\n",
    "After setting up the grid search, we fit the GridSearchCV object to our training data (X_train and y_train). This process involves training multiple models with different hyperparameter combinations and evaluating their performance using cross-validation. Our goal is to identify the set of hyperparameters that yields the highest accuracy.\n",
    "\n",
    "Once the grid search completes, we print out the best set of hyperparameters and the corresponding best score. The grid_search.best_params_ attribute provides the combination of hyperparameters that achieved the highest cross-validation accuracy, while the grid_search.best_score_ attribute shows the corresponding accuracy score. Finally, we extract the best model (best_model) from the grid search results. This model is trained with the optimal hyperparameters and is ready for making predictions or further analysis in our classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71469fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [5],\n",
    "    'learning_rate': [0.1],\n",
    "    'subsample': [0.75],\n",
    "    'n_estimators' : [50,100]\n",
    "}\n",
    "\n",
    "# Create the XGBoost model object\n",
    "xgb_model = xgb.XGBClassifier(tree_method='hist')\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f71ea36",
   "metadata": {},
   "source": [
    "#### Evaluate model performance\n",
    "\n",
    "We will use our best model to predict the classes of the test data  Then, we calculate the F1 score using f1_score, which balances precision and recall, and print it to evaluate overall performance.\n",
    "\n",
    "Next, we assess how well the model performs for predicting Pine trees by calculating its precision and recall. Precision measures the accuracy of the positive predictions.  It answers the question, \"Of all the instances we labeled as Pines, how many were actually Pines?\". Recall measures the model's ability to identify all actual positive instances. It answers the question, \"Of all the actual Pines, how many did we correctly identify?\". You may also be familiar with the terms Users' and Producers' Accuracy. Precision  = User' Accuracy, and Recall = Producers' Accuracy.\n",
    "\n",
    "Finally, we create and display a confusion matrix to visualize the model's prediction accuracy across all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20eee2-96be-4bc9-9abc-3268d2591055",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Step 2: Calculate F1 score for the entire dataset\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # 'weighted' accounts for class imbalance\n",
    "print(f\"F1 Score (weighted): {f1}\")\n",
    "\n",
    "# Step 3: Calculate precision and recall for class 3\n",
    "precision_class_3 = precision_score(y_test, y_pred, labels=[3], average='macro', zero_division=0)\n",
    "recall_class_3 = recall_score(y_test, y_pred, labels=[3], average='macro', zero_division=0)\n",
    "\n",
    "print(f\"Precision for Class 3: {precision_class_3}\")\n",
    "print(f\"Recall for Class 3: {recall_class_3}\")\n",
    "\n",
    "# Step 4: Plot the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matrix).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88a6bd1",
   "metadata": {},
   "source": [
    "ML models typically provide a single prediction of the most likely outcomes. You can also get probability-like scores (values from 0 to 1) from these models, but they are not true probabilities. If the model gives you a score of 0.6, that means it is more likely than a prediction of 0.5, and less likely than 0.7. However, it does not mean that in a large sample your prediction would be right 60 times out of 100. To get calibrated probabilities from our models, we have to apply additional steps. We can also get a set of predictions from models rather than a single prediction, which reflects the model's true uncertainty using a technique called conformal predictions. Read more about conformal prediction for geospatial machine learning in this amazing paper:\n",
    "\n",
    "[Singh, G., Moncrieff, G., Venter, Z., Cawse-Nicholson, K., Slingsby, J., & Robinson, T. B. (2024). Uncertainty quantification for probabilistic machine learning in earth observation using conformal prediction. Scientific Reports, 14(1), 16166.](https://www.nature.com/articles/s41598-024-65954-w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694182c4-6384-4907-9c99-291b07dff60f",
   "metadata": {},
   "source": [
    "#### Interpret and understand ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7aa05b-2712-465d-ae55-49eb156d3687",
   "metadata": {},
   "source": [
    "Model interpretation in machine learning is crucial for understanding how models make predictions, especially in complex models. SHAP (SHapley Additive exPlanations) scores are a popular method for interpreting model predictions. They provide a way to explain the output of any machine learning model by assigning each feature an importance value for a particular prediction.\n",
    "\n",
    "SHAP scores explain the contribution of each feature to a model's prediction using concepts from cooperative game theory. They start with a baseline prediction, which is the average prediction across all data points. For each feature, SHAP calculates how much the prediction changes when the feature is included compared to when it is not, considering all possible combinations of features. The SHAP value for a feature is the average of its contributions across all combinations, ensuring fair distribution. Positive SHAP values indicate the feature increases the prediction, while negative values suggest it decreases it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c682966-758e-4afd-8776-c1b25014da8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "#shap.initjs()\n",
    "\n",
    "# Initialize the SHAP Tree Explainer for XGBoost\n",
    "explainer = shap.TreeExplainer(best_model,feature_names=list(map(str, dsp.wavelength.values.astype(int))))\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd7c43d",
   "metadata": {},
   "source": [
    "We can select an indiviual prediction to inspect how the input features have influenced it's assignment to a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b500038",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_in = 5\n",
    "print(f'predicted class: {lab_df.loc[y_pred[sel_in],'text_lab']}')\n",
    "print(f'true class: {lab_df.loc[y_test[sel_in],'text_lab']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147fe38e-7022-43b3-a877-84f28e6fcddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[sel_in,:,y_test[sel_in]])\n",
    "\n",
    "\n",
    "#lables for wavelength in plot\n",
    "#feats =  dsp.wavelength.values.astype(int)\n",
    "#feats = map(str,feats)\n",
    "#shap.force_plot(explainer.expected_value[y_test[sel_in]], shap_values.values[sel_ind,:,y_test[sel_in]], pd.DataFrame(X_test).iloc[sel_ind, :],link='logit',feature_names=list(feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a679bf2",
   "metadata": {},
   "source": [
    "We can also inspect the importance of features across all instances of a particular class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972cd26-eef5-4d11-927f-f0a70bfd5d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values[:,:,y_test[sel_in]].abs, color=\"shap_red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d80cd",
   "metadata": {},
   "source": [
    "Finally, lets overlay this on the actual spectra for a individual observation to understand how spectral features are contributing to our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e04587-9d89-4398-9b52-27386f132635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot spectra and importance\n",
    "importance = np.abs(shap_values[sel_in,:,y_test[sel_in]].values)\n",
    "# Create the base plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Get the wavelength and importance data\n",
    "wavelength = dsp['wavelength'].values\n",
    "importance = importance  # Make sure this aligns with your wavelength data\n",
    "\n",
    "# Create a colormap\n",
    "cmap = plt.get_cmap('hot').reversed()  # You can choose a different colormap if you prefer\n",
    "\n",
    "# Normalize importance values to [0, 1] for colormap\n",
    "norm = plt.Normalize(importance.min(), importance.max())\n",
    "\n",
    "# Add shading\n",
    "for i in range(len(wavelength) - 1):\n",
    "    ax.fill_between([wavelength[i], wavelength[i+1]], 0, 1, \n",
    "                    color=cmap(norm(importance[i])), alpha=0.3)\n",
    "\n",
    "# Add a colorbar to show the importance scale\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax, label='Importance')\n",
    "\n",
    "# Add white blocks to obscure specified regions\n",
    "ax.fill_between([0,420], 0, 1, color='white')\n",
    "ax.fill_between([1340,1458], 0, 1, color='white')\n",
    "ax.fill_between([1800,1980], 0, 1, color='white')\n",
    "ax.fill_between([2400,2500], 0, 1, color='white')\n",
    "ax.set_xlim(420,2400)\n",
    "\n",
    "plot_xr = xr.DataArray(X_test[sel_in], coords=[wavelength], dims=[\"wavelength\"])\n",
    "plot_xr.plot.line(x='wavelength', color='green', ylim=(0, 0.2), ax=ax,zorder=0)\n",
    "\n",
    "plt.title('Reflectance with Importance Shading')\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Reflectance (normalized)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ea5c8f-fd79-4572-b22a-b7e7b997d5bf",
   "metadata": {},
   "source": [
    "#### Predict over multiple AVIRIS scenes\n",
    "\n",
    "We now have a trained model and are ready to deploy it to generate predictions across an entire AVIRIS scene and map the distribution of invasive plants. This involves handling a large volume of data, so we need to write the code to do this intelligently. We will accomplish this by applying the `.predict()` method of our trained model in parallel across the chunks of the AVIRIS xarray. The model will receive one chunk at a time so that the data is not too large, but it will be able to perform this operation in parallel across multiple chunks, and therefore will not take too long."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8aabf0",
   "metadata": {},
   "source": [
    "Our model was only trained on data covering natural vegetaiton in the Cape Peninsula, It is important that we only predict in the areas that match our training data. We will therefore filter to scenes that cover the Cape Peninsula and mask out non-protected areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c154fb9-8ada-480b-86e2-1d2edfe4795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#south africa protected areas\n",
    "SAPAD = (gpd.read_file('shared/users/gmoncrieff/data/SAPAD_2024.gpkg')\n",
    "         .query(\"SITE_TYPE!='Marine Protected Area'\")\n",
    "        )\n",
    "\n",
    "# Get the bounding box of the training data\n",
    "bbox = raw_data.total_bounds  # (minx, miny, maxx, maxy)\n",
    "gdf_bbox = gpd.GeoDataFrame({'geometry': [box(*bbox)]}, crs=raw_data.crs)  # Specify the CRS\n",
    "gdf_bbox['geometry'] = gdf_bbox.buffer(0.02)\n",
    "\n",
    "# protected areas that intersect with the training data\n",
    "SAPAD_CT = SAPAD.overlay(gdf_bbox,how='intersection')\n",
    "\n",
    "#keep only AVIRIS scenes that intersects with CT protected areas\n",
    "AVNG_sapad = AVNG_CP[AVNG_CP.intersects(SAPAD_CT.union_all())]\n",
    "\n",
    "#a list of files to predict\n",
    "files_sapad = AVNG_sapad['RFL s3'].tolist()\n",
    "\n",
    "#remove 2 files that mess things up. Dunno why\n",
    "files_sapad.pop(85)\n",
    "files_sapad.pop(87)\n",
    "\n",
    "#get the geometries of the protected areas for masking later\n",
    "geometries_sapad = SAPAD_CT.to_crs(\"EPSG:32734\").geometry.apply(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642bdc71",
   "metadata": {},
   "source": [
    "Lets see where we will be predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8a116-527e-4161-9917-c2a73ad28cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAPAD_CT.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9856147",
   "metadata": {},
   "source": [
    "Here is the function that we will actually apply to each chunk. Simple really. The hard work is getting the data into and out of this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a63d9-46f8-41c1-bad4-60104a83c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_chunk(chunk, model):\n",
    "    probabilities = model.predict_proba(chunk)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ffffdb",
   "metadata": {},
   "source": [
    "Now we define the funciton that takes as input the path to the AVIRIS file and pass the data to the predict function. THhs is composed of 4 parts:\n",
    "\n",
    "Part 1: Opens the AVIRIS data file using xarray and sets a condition to identify valid data points where reflectance values are greater than zero.\n",
    "\n",
    "Part 2: Applies all the transformations that need to be done before the data goes to the model. It the spatial dimensions (x and y) into a single dimension, filters wavelengths, and normalizes the reflectance data.\n",
    "\n",
    "Part 3: Applies the machine learning model to the normalized data in parallel, predicting class probabilities for each data point using xarray's apply_ufunc method. Most of the function invloves defining what to do with the dimensions of the old dataset and the new output\n",
    "\n",
    "Part 4: Unstacks the data to restore its original dimensions, sets spatial dimensions and coordinate reference system (CRS), clips the data, and transposes the data to match expected formats before returning the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41debacf-b44f-4960-8266-74bc8fdf0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_xr(file,geometries):\n",
    "\n",
    "    #part 1 - opening file\n",
    "    #open the file\n",
    "    print(f'file: {file}')\n",
    "    ds = xr.open_dataset(file, engine='kerchunk', chunks='auto')\n",
    "\n",
    "    #condition to use for masking no data later\n",
    "    condition = (ds['reflectance'] > 0).any(dim='wavelength')\n",
    "\n",
    "    #stack the data into a single dimension. This will be important for applying the model later\n",
    "    ds = ds.stack(sample=('x','y'))\n",
    "    \n",
    "    #part 2 - pre-processing\n",
    "    #remove bad wavelenghts\n",
    "    wavelengths_to_drop = ds.wavelength.where(\n",
    "        (ds.wavelength < 420) |\n",
    "        (ds.wavelength >= 1340) & (ds.wavelength <= 1450) |\n",
    "        (ds.wavelength >= 1800) & (ds.wavelength <= 1980) |\n",
    "        (ds.wavelength > 2400), drop=True\n",
    "    )\n",
    "    # Use drop_sel() to remove those specific wavelength ranges\n",
    "    ds = ds.drop_sel(wavelength=wavelengths_to_drop)\n",
    "    \n",
    "    #normalise the data\n",
    "    l2_norm = np.sqrt((ds['reflectance'] ** 2).sum(dim='wavelength'))\n",
    "    ds['reflectance'] = ds['reflectance'] / l2_norm\n",
    "    \n",
    "    #part 3 - apply the model over chunks\n",
    "    result = xr.apply_ufunc(\n",
    "        predict_on_chunk,\n",
    "        ds['reflectance'],\n",
    "        input_core_dims=[['wavelength']],#input dim with features\n",
    "        output_core_dims=[['class']],  # name for the new output dim\n",
    "        exclude_dims=set(('wavelength',)),  #dims to drop in result\n",
    "        output_sizes={'class': 9}, #length of the new dimension\n",
    "        output_dtypes=[np.float32],\n",
    "        dask=\"parallelized\",\n",
    "        kwargs={'model': best_model}\n",
    "    )\n",
    "\n",
    "    #part 4 - post-processing\n",
    "    result = result.unstack('sample') #remove the stack\n",
    "    result = result.rio.set_spatial_dims(x_dim='x',y_dim='y') #set the spatial dims\n",
    "    result = result.rio.write_crs(\"EPSG:32734\") #set the CRS\n",
    "    result = result.rio.clip(geometries).where(condition) #clip to the protected areas and no data\n",
    "    result = result.transpose('class', 'y', 'x') #transpose the data rio expects it this way\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa7bcdb",
   "metadata": {},
   "source": [
    "Before we blast through 100s of GB of data, lets test that it works on a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2bff7d-cd87-43a8-a8d5-09cd99862c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test  = predict_xr(files_sapad[53],geometries_sapad)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa707bb",
   "metadata": {},
   "source": [
    "Pretty good. Lets look at the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71497790-f98a-44e3-9243-b17c636cc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.rio.reproject(\"EPSG:4326\")\n",
    "test.isel({'class':0}).hvplot(tiles=hv.element.tiles.EsriImagery(), \n",
    "                              project=True,rasterize=True,robust=True,\n",
    "                              cmap='magma',frame_width=400,data_aspect=1,alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4669ff",
   "metadata": {},
   "source": [
    "OK, now we are ready to go. This wont take long, as we have not yet ask it to perform the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def8f636-ddf3-4bdd-aa4c-b18fe7a42a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pred = [predict_xr(fi,geometries_sapad) for fi in files_sapad]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d50e9c-d6a0-47d2-86ca-f416a1e6b0f4",
   "metadata": {},
   "source": [
    "#### Merge and mosaic results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2d83f4",
   "metadata": {},
   "source": [
    "The results are now available as a list of xarrays, one for each scence. We want to combine these together into a single seamless mosaic for the entire Cape Peninsula. Fortunatley we dont have to write a ton of code to do this as `rioxarray` already has a mosaic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c79675-2581-4a57-992e-d9eaa4811053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rioxarray.merge import merge_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd492538",
   "metadata": {},
   "source": [
    "This will force computation and take about 10-30 mins to run on a 4 core, 16GB RAM machine. We wont run this, but rather load the result I computed earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f03f2b-01b0-4e3f-b3c6-711eeb056a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged = merge_arrays(grid_pred)\n",
    "#merged = merged.rio.reproject(\"EPSG:4326\")\n",
    "#merged.rio.to_raster('data/ct_invasive.tiff',driver=\"COG\")\n",
    "\n",
    "merged = xr.open_dataset('shared/users/gmoncrieff/data/ct_invasive.tiff', engine='rasterio', chunks='auto')\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cd19d8",
   "metadata": {},
   "source": [
    "view the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04d01b-fab5-494a-a3ca-b5132e62c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.isel({'band':6}).hvplot(x='x',y='y',tiles=hv.element.tiles.EsriImagery(),\n",
    "                               geo=True,\n",
    "                                project=True,rasterize=True,robust=True,\n",
    "                                cmap='magma',clim=(0,1), frame_width=400,data_aspect=1,alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca17852",
   "metadata": {},
   "source": [
    "> Now we can inspect our results. Where do they look good? Where do bthey look bad? We should at this point return to the beginning of our workflow and refine every step of the process. Probably most importantly we should update our training data to include points that correct the errors that we see in our earlier outputs. This proicess of using early predictions to update our data is called 'Active Learning'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c1b457",
   "metadata": {},
   "source": [
    "### credits\n",
    "\n",
    "This lesson has borrowed from:    \n",
    "\n",
    "[Land cover mapping example on Microsoft Planetary Computer](https://planetarycomputer.microsoft.com/docs/tutorials/landcover) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmoncrieff-gmoncrieff-ml",
   "language": "python",
   "name": "conda-env-gmoncrieff-gmoncrieff-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
